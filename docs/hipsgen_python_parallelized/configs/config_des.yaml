# =============================================================================
# HiPS Catalog Pipeline — config.yaml
# =============================================================================
# Configuration file for Hipsgen-cat.py
#
# The pipeline:
#   - Reads large catalogs (Parquet / CSV / TSV / HATS)
#   - Distributes data with Dask or LSDB (depending on format)
#   - Selects sources per HEALPix coverage cell (__icov__)
#   - Writes HiPS-compliant tiles (Norder*/Dir*/Npix*.tsv)
#   - Produces MOC, density maps, metadata, and logs
#
# HATS catalogs:
#   - Opened via lsdb.open_catalog()
#   - Preserve LSDB structure and HEALPix partitioning
#   - Use existing HEALPix index (_healpix_<order>) for __icov__ and density maps
#   - Skip repartitioning and shuffle to ensure consistency
# =============================================================================


# -----------------------------------------------------------------------------
# Input catalog(s)
# -----------------------------------------------------------------------------
input:
  # Input file(s) or directories (supports wildcards).
  # Parquet/CSV/TSV → file paths; HATS → root catalog folder.
  paths:
    - "/scratch/users/luigi.silva/curso-hpc/des_dr2_cut_spatial/*.parquet"

  # Format: "parquet", "csv", "tsv", or "hats"
  format: parquet

  # For CSV/TSV:
  #   header: true  → first row has column names
  #   header: false → positional columns (RA/DEC/score as 1-based indices)
  # header: true

  # Optional hint for ASCII formats (usually not needed).
  # ascii_format: CSV


# -----------------------------------------------------------------------------
# Column mapping and score definition
# -----------------------------------------------------------------------------
columns:
  # RA/DEC column names or 1-based indices (if no header).
  ra: RA
  dec: DEC

  # Score expression to rank sources within each coverage cell/tile.
  # Example: "MAG_I" or "(FLUX_R / ERR_R)**2"
  # order_desc=false → lower is better; true → higher is better.
  score: "MAG_AUTO_I_DERED"

  # Optional explicit list of columns to keep in output tiles.
  # If omitted, keeps RA/DEC, score-related, and all input columns.
  keep:
    - MAG_AUTO_G_DERED
    # - MAG_AUTO_R_DERED
    # - ...


# -----------------------------------------------------------------------------
# Algorithmic controls
# -----------------------------------------------------------------------------
algorithm:
  # Maximum HiPS order (1..level_limit); tiles written for all levels ≤ this.
  level_limit: 11

  # HEALPix order for MOC and coverage density map.
  level_coverage: 10

  # HEALPix order for coverage cells (__icov__); higher = finer uniformity.
  # ⚠️ Note: if you *decrease* coverage_order (larger cells), consider
  # increasing k_per_cov_initial — otherwise, the number of selected
  # objects per level may become too small.
  coverage_order: 10

  # Score ordering: false → ascending (lower better); true → descending.
  order_desc: false

  # Density variation with depth:
  # "constant", "linear", "exp", or "log"
  density_mode: "exp"

  # Base expected number of rows per coverage cell at depth 1.
  # Tip: tune together with coverage_order to balance per-level population.
  k_per_cov_initial: 0.05

  # Growth factor for "exp" density mode (e.g., 2 → doubles per level).
  density_exp_base: 2

  # Optional per-level overrides for expected rows per coverage cell.
  # Keys = depth (Norder), values = float.
  # k_per_cov_per_level:
  #   3: 0.5
  #   5: 2.0
  #   7: 5.0

  # Optional global caps: total target rows per depth (Norder → count).
  # targets_total_per_level:
  #   1: 1000
  #   2: 2000
  #   3: 4000

  # Fractional mode:
  # "random" → probabilistic per-coverage;
  # "score" → global best-score preference.
  fractional_mode: "score"

  # Extra candidates per coverage cell near cutoff (helps avoid artifacts).
  tie_buffer: 2


# -----------------------------------------------------------------------------
# Cluster settings (Dask or SLURM)
# -----------------------------------------------------------------------------
cluster:
  # Execution mode: "local" (LocalCluster) or "slurm" (SLURMCluster)
  mode: slurm

  # Dask worker configuration
  n_workers: 20
  threads_per_worker: 8
  memory_per_worker: "12GB"

  # Memory vs throughput presets:
  #   Low-memory  → persist_ddfs: false, avoid_computes_wherever_possible: true
  #   High-speed  → persist_ddfs: true,  avoid_computes_wherever_possible: false
  persist_ddfs: false
  avoid_computes_wherever_possible: true

  # SLURM options (only used if mode: slurm)
  slurm:
    queue: "cpu_small"
    account: "hpc-bpglsst"
    job_extra_directives:
      - "--partition=cpu_small"
      - "--time=02:00:00"
    # Optional extras:
    # - "--constraint=..."
    # - "--qos=..."
    # - "--mem=0"   # use all node memory if allowed

    # Dask performance reports:
    # "none" → disabled, "local" → per-depth, "global" → full pipeline
    diagnostics_mode: global


# -----------------------------------------------------------------------------
# Output settings
# -----------------------------------------------------------------------------
output:
  # Output root directory for the HiPS hierarchy.
  out_dir: "/scratch/users/luigi.silva/hipsgencat/DES_DR2_small_sample"

  # Catalog / HiPS name (used in metadata and folder names).
  cat_name: "DES_DR2_small_sample"

  # Default sky position for visualization (RA DEC, degrees).
  target: "0 0"