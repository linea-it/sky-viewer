# =============================================================================
# HiPS Catalog Pipeline — config.yaml (Template)
# =============================================================================
# Configuration file for Hipsgen-cat.py
#
# This pipeline:
#   - reads a large input catalog (Parquet / CSV / TSV / HATS),
#   - distributes it with Dask or LSDB (depending on format),
#   - selects sources per HEALPix coverage cell (__icov__),
#   - writes HiPS-compliant tiles (Norder*/Dir*/Npix*.tsv),
#   - produces MOC, densmaps, metadata, and logs.
#
# The pipeline supports both traditional Dask-based catalogs (Parquet/CSV/TSV)
# and LSDB-based HATS catalogs:
#   * If input.format = "hats", the catalog is opened using lsdb.open_catalog().
#   * HATS catalogs preserve their native LSDB structure and HEALPix partitioning.
#   * The pipeline automatically detects the existing HEALPix index
#     (_healpix_<order>) and derives __icov__ and density maps directly from it.
#   * No repartitioning or shuffle operations are applied when format="hats",
#     ensuring full consistency with the LSDB structure.
# =============================================================================


# -----------------------------------------------------------------------------
# Input catalog(s)
# -----------------------------------------------------------------------------
input:
  # One or more glob patterns for input files.
  # You can specify multiple directories or files using wildcards.
  #   - For parquet/csv/tsv: paths should point to the actual files.
  #   - For hats: paths should point to the root folder of the HATS catalog.
  paths:
    - "/path/to/your/catalog/*.parquet"

  # File format: "parquet", "csv", "tsv", or "hats".
  #   - parquet / csv / tsv → read using Dask
  #   - hats                → open LSDB catalog via lsdb.open_catalog()
  format: parquet

  # For CSV/TSV:
  #   header: true  → first row has column names
  #   header: false → no header; RA/DEC/score can then be given as 1-based indices
  # header: true

  # Optional hint for ASCII formats ("CSV" or "TSV"); usually not needed.
  # ascii_format: CSV


# -----------------------------------------------------------------------------
# Column mapping and score definition
# -----------------------------------------------------------------------------
columns:
  # RA/DEC columns; can be names (for Parquet or CSV with header)
  # or 1-based indices as strings (e.g., "1", "2") for ASCII without header.
  ra: ra
  dec: dec

  # Score used to rank sources within each coverage cell and tile.
  # - It can be a simple column name (e.g., "mag_r").
  # - Or a Python expression using existing columns, e.g.:
  #     "(flux_g / err_g)**2"
  # - With order_desc: false, lower scores are better (ascending).
  # - With order_desc: true, higher scores are better (descending).
  score: "mag_r"

  # Optional explicit list of columns to keep in the output tiles.
  # If omitted, the pipeline will:
  #   - keep RA, DEC, and all columns required by "score",
  #   - plus all other input columns in their original order.
  keep:
    - ra
    - dec
    - mag_g
    - mag_r


# -----------------------------------------------------------------------------
# Algorithmic controls
# -----------------------------------------------------------------------------
algorithm:
  # --------------------------
  # HiPS / coverage depth
  # --------------------------
  # level_limit: maximum HiPS order (NorderL).
  # Tiles are produced for Norder=1..level_limit.
  level_limit: 8

  # level_coverage: HEALPix order used for:
  #   - the coverage/MOC generation,
  #   - densmap_o<order>.fits used for the MOC.
  # If only one of level_coverage / coverage_order is given in the YAML,
  # the code will use that value for the other as a default.
  level_coverage: 8

  # coverage_order: HEALPix order used to define __icov__ coverage cells.
  # Higher values → smaller cells → finer uniformity control.
  coverage_order: 8

  # order_desc:
  #   false → ascending score (lower is better)
  #   true  → descending score (higher is better)
  order_desc: false

  # --------------------------
  # Density control
  # --------------------------
  # density_mode controls how the expected number of rows per coverage
  # cell varies with depth:
  #
  #   "constant" → same expected density at all depths
  #   "linear"   → grows linearly with depth
  #   "exp"      → grows exponentially with depth
  #   "log"      → grows slowly, ~log(depth)
  #
  # At each depth, the pipeline computes a "k_desired" which is the
  # expected number of rows per coverage cell (__icov__), before
  # per-level overrides and global caps are applied.
  density_mode: "exp"

  # k_per_cov_initial:
  #   Expected number of rows per coverage cell (__icov__) at depth = 1.
  #   This is the base of the density profile.
  #
  # Example:
  #   - constant, k_per_cov_initial: 1.0 → ~1 row per coverage cell at all depths
  #   - exp, k_per_cov_initial: 0.05 → very sparse at shallow depth, denser at deep
  k_per_cov_initial: 0.05

  # density_exp_base:
  #   Only used when density_mode: "exp".
  #   Controls how quickly the density grows with depth.
  #   Example: base=2 → roughly doubles per depth.
  density_exp_base: 2

  # k_per_cov_per_level:
  #   Optional per-depth hard overrides for k_desired.
  #   Keys are depths (Norder), values are floats (can be fractional).
  #   If defined for a given depth, this overrides density_mode/k_per_cov_initial
  #   at that depth.
  #
  # Example (uncomment to use):
  # k_per_cov_per_level:
  #   3: 0.5      # depth 3: ~0.5 expected rows per coverage cell
  #   5: 2.0      # depth 5: ~2.0 expected rows per coverage cell
  #   7: 5.0

  # targets_total_per_level:
  #   Optional global caps on the TOTAL number of rows at each depth.
  #   Keys are depths (Norder), values are total row counts (integers).
  #
  # Example (uncomment to use):
  # targets_total_per_level:
  #   1: 1000
  #   2: 2000
  #   3: 4000

  # fractional_mode:
  #   Controls how the fractional part of k_desired is handled.
  #   "random" → uniform per-coverage behavior
  #   "score"  → global best-score behavior
  fractional_mode: "score"   # or "random"

  # tie_buffer:
  #   Extra candidates per coverage cell around the cutoff.
  #   Small values (2–10) help avoid artifacts near the cutoff.
  tie_buffer: 2


# -----------------------------------------------------------------------------
# Dask cluster settings
# -----------------------------------------------------------------------------
cluster:
  # "local" → LocalCluster on the current node
  # "slurm" → SLURMCluster via dask_jobqueue (requires a working SLURM environment)
  mode: local

  # Number of workers and threads per worker
  n_workers: 8
  threads_per_worker: 4

  # Memory limit per worker (string recognized by Dask, e.g., "4GB", "12GB")
  memory_per_worker: "8GB"

  # ----------------------------
  # Performance / memory tuning
  # ----------------------------
  # Recommended presets:
  #   • Low-memory mode  → persist_ddfs: false, avoid_computes_wherever_possible: true
  #   • High-throughput mode → persist_ddfs: true, avoid_computes_wherever_possible: false
  persist_ddfs: false
  avoid_computes_wherever_possible: true

  # ----------------------------
  # SLURM-specific options (used only when mode: "slurm")
  # ----------------------------
  slurm:
    queue: "cpu"
    account: "your-account"
    job_extra_directives:
      - "--partition=cpu"
      - "--time=02:00:00"
    # Additional examples:
    #   - "--constraint=..."
    #   - "--qos=..."
    #   - "--mem=0"   # use all node memory (if allowed)


# -----------------------------------------------------------------------------
# Output location and metadata
# -----------------------------------------------------------------------------
output:
  # Root directory where the HiPS structure will be written.
  out_dir: "/path/to/output/hips_catalog"

  # Catalogue / HiPS name; used in properties and path names.
  cat_name: "My_HiPS_Catalog"

  # Initial sky position for visualization tools (degrees).
  # Used only in the properties file.
  # Format: "<RA0> <DEC0>"
  target: "0 0"
